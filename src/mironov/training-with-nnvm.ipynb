{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's train some simple models in pure nnvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nnvm\n",
    "import nnvm.symbol as sym\n",
    "from nnvm.compiler.graph_util import gradients\n",
    "from nnvm.compiler.optimizer import SGD\n",
    "\n",
    "import tvm\n",
    "from tvm.contrib import graph_runtime\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need keras because it is the easiest way to load datasets I know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nix/store/p3i9s3vhjskbrnfl97fd7b0vmn7bqddh-python3.6-h5py-2.7.1/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches(batch_size, x=x_train, y=y_train, repeat=True):\n",
    "    while True:\n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            yield (x[i:i+batch_size, ...].astype('float32')/255.0, \n",
    "                   np.eye(10)[y[i:i+batch_size]].astype('float32'))\n",
    "        if not repeat:\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "v_images = sym.Variable(\"images\", shape=(BATCH_SIZE, 1, 28, 28), dtype=0)\n",
    "v_true_labels = sym.Variable(\"true_labels\", shape=(BATCH_SIZE, 10), dtype=0)\n",
    "\n",
    "x = v_images\n",
    "x = sym.reshape(data=x, shape=(BATCH_SIZE, 28*28))\n",
    "x = sym.dense(data=x, units=10)\n",
    "logits = x\n",
    "\n",
    "x = - sym.elemwise_mul(v_true_labels, sym.log_softmax(x))\n",
    "loss = sym.sum(x) / BATCH_SIZE\n",
    "\n",
    "# This is not really accuracy, because we use softmax instead of hardmax\n",
    "accuracy = sym.sum(v_true_labels * sym.softmax(logits)) / BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two graphs: `graph` for training and `forward_graph` for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to somehow list all weights (the corresponding variables are generated automatically)\n",
    "weight_vars = [v for v in loss.list_input_variables() if v.attr('name') not in ['images', 'true_labels']]\n",
    "\n",
    "optimizer = SGD(learning_rate=1e-4)\n",
    "update_step = optimizer.minimize(loss, var=weight_vars)\n",
    "\n",
    "graph = nnvm.graph.create(sym.Group([loss, update_step])).apply(\"InferShape\").apply(\"InferType\")\n",
    "forward_graph = nnvm.graph.create(sym.Group([loss, accuracy])).apply(\"InferShape\").apply(\"InferType\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(graph.ir(join_node_attrs=['shape', 'dtype']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile both graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgraph, libmod, params = nnvm.compiler.build(graph, 'llvm')\n",
    "m = graph_runtime.create(cgraph, libmod, tvm.cpu(0))\n",
    "fcgraph, flibmod, fparams = nnvm.compiler.build(forward_graph, 'llvm')\n",
    "fm = graph_runtime.create(fcgraph, flibmod, tvm.cpu(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly initialize weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing true_labels [32, 10]\n",
      "Initializing images [32, 1, 28, 28]\n",
      "Initializing dense0_weight [10, 784]\n",
      "Initializing dense0_bias [10]\n"
     ]
    }
   ],
   "source": [
    "if params:\n",
    "    m.set_input(**params)\n",
    "    \n",
    "if fparams:\n",
    "    fm.set_input(**fparams)\n",
    "\n",
    "shapes = graph.json_attr('shape')\n",
    "    \n",
    "for v in loss.list_input_variables():\n",
    "    shape = shapes[graph.index.node_id(v.attr('name'))]\n",
    "    print(\"Initializing \" + str(v.attr('name')) + \" \" + str(shape))\n",
    "    m.set_input(v.attr('name'), np.random.normal(scale=0.1, size=shape).astype('float32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This functions runs the forward graph on the test data using current weights from the training graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    # copy weights from training to inference. Not sure if we can avoid it and still run only the inference part (without grads)\n",
    "    for v in weight_vars:\n",
    "        shape = shapes[graph.index.node_id(v.attr('name'))]\n",
    "        # note that we use get_input: _assign mutates the input variable\n",
    "        fm.set_input(v.attr('name'), m.get_input(v.attr('name'), tvm.nd.empty(shape)))\n",
    "    \n",
    "    loss = []\n",
    "    acc = []\n",
    "    \n",
    "    for b in batches(BATCH_SIZE, x_test, y_test, repeat=False):\n",
    "        fm.set_input('images', b[0][:, None, ...])\n",
    "        fm.set_input('true_labels', b[1])\n",
    "        fm.run()\n",
    "        loss.append(fm.get_output(0, tvm.nd.empty((1,))).asnumpy()[0])\n",
    "        acc.append(fm.get_output(1, tvm.nd.empty((1,))).asnumpy()[0])\n",
    "    \n",
    "    return np.mean(loss), np.mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 seen: 0 tr loss: inf\n",
      "test loss: 2.605138 test accuracy: 0.104033045\n",
      "step: 1000 seen: 32000 tr loss: [2.5119948]\n",
      "step: 2000 seen: 64000 tr loss: [2.2600343]\n",
      "step: 3000 seen: 96000 tr loss: [2.3432593]\n",
      "step: 4000 seen: 128000 tr loss: [2.0252519]\n",
      "step: 5000 seen: 160000 tr loss: [1.9078416]\n",
      "step: 6000 seen: 192000 tr loss: [1.8912483]\n",
      "step: 7000 seen: 224000 tr loss: [1.8423703]\n",
      "step: 8000 seen: 256000 tr loss: [1.8401768]\n",
      "step: 9000 seen: 288000 tr loss: [1.888246]\n",
      "step: 10000 seen: 320000 tr loss: [1.7447925]\n",
      "test loss: 1.8121912 test accuracy: 0.19732629\n",
      "step: 11000 seen: 352000 tr loss: [1.4131862]\n",
      "step: 12000 seen: 384000 tr loss: [1.6707991]\n",
      "step: 13000 seen: 416000 tr loss: [1.4810647]\n",
      "step: 14000 seen: 448000 tr loss: [1.3933669]\n",
      "step: 15000 seen: 480000 tr loss: [1.4294233]\n",
      "step: 16000 seen: 512000 tr loss: [1.4877458]\n",
      "step: 17000 seen: 544000 tr loss: [1.4209709]\n",
      "step: 18000 seen: 576000 tr loss: [1.6107997]\n",
      "step: 19000 seen: 608000 tr loss: [1.2538222]\n",
      "step: 20000 seen: 640000 tr loss: [1.1649357]\n",
      "test loss: 1.4322042 test accuracy: 0.292624\n",
      "step: 21000 seen: 672000 tr loss: [1.1384443]\n",
      "step: 22000 seen: 704000 tr loss: [1.2058543]\n",
      "step: 23000 seen: 736000 tr loss: [1.3042473]\n",
      "step: 24000 seen: 768000 tr loss: [1.3011968]\n",
      "step: 25000 seen: 800000 tr loss: [1.2943712]\n",
      "step: 26000 seen: 832000 tr loss: [0.8934825]\n",
      "step: 27000 seen: 864000 tr loss: [1.1636425]\n",
      "step: 28000 seen: 896000 tr loss: [1.0152909]\n",
      "step: 29000 seen: 928000 tr loss: [1.0544132]\n",
      "step: 30000 seen: 960000 tr loss: [1.0323465]\n",
      "test loss: 1.2167506 test accuracy: 0.36305192\n",
      "step: 31000 seen: 992000 tr loss: [1.1493511]\n",
      "step: 32000 seen: 1024000 tr loss: [1.1003009]\n",
      "step: 33000 seen: 1056000 tr loss: [1.2941073]\n",
      "step: 34000 seen: 1088000 tr loss: [0.9695951]\n",
      "step: 35000 seen: 1120000 tr loss: [0.8432675]\n",
      "step: 36000 seen: 1152000 tr loss: [0.82837427]\n",
      "step: 37000 seen: 1184000 tr loss: [0.9695984]\n",
      "step: 38000 seen: 1216000 tr loss: [1.0865467]\n",
      "step: 39000 seen: 1248000 tr loss: [1.0507979]\n",
      "step: 40000 seen: 1280000 tr loss: [1.0893703]\n",
      "test loss: 1.0794674 test accuracy: 0.41519845\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-54a21be41acf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mseen\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtr_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/proj/mytvm/python/tvm/_ffi/ndarray.py\u001b[0m in \u001b[0;36mempty\u001b[0;34m(shape, dtype, ctx)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0marray\u001b[0m \u001b[0mtvm\u001b[0m \u001b[0msupported\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtvm_shape_index_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTVMArrayHandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/proj/mytvm/python/tvm/_ffi/base.py\u001b[0m in \u001b[0;36mc_array\u001b[0;34m(ctype, values)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mc_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \"\"\"Create ctypes array from a python array\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seen = 0\n",
    "tr_loss = np.inf\n",
    "for i, b in enumerate(batches(BATCH_SIZE)):\n",
    "    if i % 1000 == 0:\n",
    "        print(\"step:\", i, \"seen:\", seen, \"tr loss:\", tr_loss)\n",
    "        \n",
    "        if i % 10000 == 0:\n",
    "            l, a = test()\n",
    "            print(\"test loss:\", l, \"test accuracy:\", a)\n",
    "    \n",
    "    # load data\n",
    "    m.set_input('images', b[0][:, None, ...])\n",
    "    m.set_input('true_labels', b[1])\n",
    "    # run a training step\n",
    "    m.run()\n",
    "    \n",
    "    seen += b[0].shape[0]\n",
    "    tr_loss = m.get_output(0, tvm.nd.empty((1,))).asnumpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
